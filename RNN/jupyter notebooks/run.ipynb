{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-j4V6fV2Jw7Z",
    "outputId": "49a5e4ec-7883-4e14-99fb-283cb3a01b0b"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fz4tjsurZ7HN"
   },
   "source": [
    "https://pytorch.org/tutorials/beginner/chatbot_tutorial.html?highlight=text%20generation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "akHYXpkCI8D2"
   },
   "source": [
    "import argparse\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "from format_data import datafiles, split_path\n",
    "from train import run\n",
    "from model import EncoderRNN, LuongAttnDecoderRNN\n",
    "from serialization import save_seq2seq, load_encoder, load_decoder, load_voc, load_embedding\n",
    "from chat import GreedySearchDecoder, chat"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6a2lZNfwLCmJ"
   },
   "source": [
    "def write_results(data_type, run_mode, encoder, encoder_name, decoder_name, dropout, clip, lr, losses):\n",
    "    os.makedirs(\"txt_results\", exist_ok=True)\n",
    "    with open(f\"txt_results{os.path.sep}\"\n",
    "              f\"{data_type}_\"\n",
    "              f\"{run_mode}_\"\n",
    "              f\"{encoder_name}{'2' if encoder.bidirectional else '1'}{decoder_name}_\"\n",
    "              f\"d{dropout}_gc{clip}_lr{lr}.txt\", \"w\") as output_file:\n",
    "        for loss in losses:\n",
    "            output_file.write(f\"{str(round(loss, 5))}\\n\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    phase = {\n",
    "        \"train\": {\"pairs\": []},\n",
    "        \"test\": {\"pairs\": []}\n",
    "    }\n",
    "\n",
    "    if run_mode == 'train':\n",
    "        with open(\"formatted_movie_QR_lines_train.txt\", \"r\") as file_obj:\n",
    "            for line in file_obj:\n",
    "                phase[\"train\"][\"pairs\"].append(line.split(\"\\n\")[0].split(\"\\t\"))\n",
    "        with open('voc.pickle', \"rb\") as f:\n",
    "            phase[\"train\"][\"voc\"] = pickle.load(f)\n",
    "\n",
    "        # Shuffle both sets ONCE before the entire training\n",
    "        random.seed(1)  # seed can be any number\n",
    "        random.shuffle(phase[\"train\"][\"pairs\"])\n",
    "\n",
    "        print('Building training set encoder and decoder ...')\n",
    "        # Initialize word embeddings for both encoder and decoder\n",
    "        embedding = nn.Embedding(phase[\"train\"][\"voc\"].num_words, HIDDEN_SIZE).to(device)\n",
    "\n",
    "        # Initialize encoder & decoder models\n",
    "        encoder = EncoderRNN(HIDDEN_SIZE, embedding, ENCODER_N_LAYERS, DROPOUT, gate=encoder_name,\n",
    "                             bidirectional=BIDIRECTION)\n",
    "        decoder = LuongAttnDecoderRNN(attn_model, embedding, HIDDEN_SIZE,\n",
    "                                      phase[\"train\"][\"voc\"].num_words, DECODER_N_LAYERS, DROPOUT, gate=decoder_name)\n",
    "\n",
    "        # Use appropriate device\n",
    "        encoder = encoder.to(device)\n",
    "        decoder = decoder.to(device)\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        print('Models built and ready to go!')\n",
    "\n",
    "        # Initialize optimizers\n",
    "        print('Building optimizers ...')\n",
    "        if args.get('optimizer') == \"ADAM\":\n",
    "            encoder_optimizer = optim.Adam(encoder.parameters(), lr=LR, weight_decay=WD)\n",
    "            decoder_optimizer = optim.Adam(decoder.parameters(), lr=LR, weight_decay=WD)\n",
    "        elif args.get('optimizer') == \"SGD\":\n",
    "            encoder_optimizer = optim.SGD(encoder.parameters(), lr=LR)\n",
    "            decoder_optimizer = optim.SGD(decoder.parameters(), lr=LR)\n",
    "        else:\n",
    "            raise ValueError(\"Wrong optimizer type has been given as an argument.\")\n",
    "\n",
    "        # If you have cuda, configure cuda to call\n",
    "        for optimizer in [encoder_optimizer, decoder_optimizer]:\n",
    "            for state in optimizer.state.values():\n",
    "                for k, v in state.items():\n",
    "                    if isinstance(v, torch.Tensor):\n",
    "                        state[k] = v.cuda()\n",
    "\n",
    "        print(\"Starting Training!\")\n",
    "        save_model = run(encoder, decoder, encoder_optimizer, decoder_optimizer, EPOCH_NUM, BATCH_SIZE, CLIP, phase)\n",
    "        save_model = True\n",
    "        if save_model:\n",
    "            try:\n",
    "                save_seq2seq(encoder, decoder, encoder_name, decoder_name, encoder_optimizer, decoder_optimizer,\n",
    "                             phase[\"train\"][\"losses\"], phase[\"train\"][\"bleu\"], phase[\"train\"][\"voc\"],\n",
    "                             embedding, DROPOUT, CLIP, LR)\n",
    "                print(\"Model has been saved successfully.\")\n",
    "            except Exception as error:\n",
    "                print(\"Saving the model has caused an exception:\", error)\n",
    "\n",
    "        write_results(\"loss\", \"train\", encoder, encoder_name, decoder_name, DROPOUT, CLIP, WD, phase[\"train\"][\"losses\"])\n",
    "        write_results(\"bleu\", \"train\", encoder, encoder_name, decoder_name, DROPOUT, CLIP, WD, phase[\"train\"][\"bleu\"])\n",
    "\n",
    "    else:\n",
    "        # Loading basic objects needed for all 3 of validation, testing and chatting\n",
    "        checkpoint = torch.load(args.get('model_path'))\n",
    "        embedding = load_embedding(checkpoint, HIDDEN_SIZE)\n",
    "        encoder = load_encoder(checkpoint, EncoderRNN, HIDDEN_SIZE, embedding,\n",
    "                               ENCODER_N_LAYERS, DROPOUT, encoder_name, BIDIRECTION)\n",
    "        voc = load_voc(checkpoint)\n",
    "        decoder = load_decoder(checkpoint, LuongAttnDecoderRNN,\n",
    "                               attn_model, embedding, HIDDEN_SIZE, voc.num_words, DECODER_N_LAYERS, DROPOUT, decoder_name)\n",
    "        encoder = encoder.to(device)\n",
    "        decoder = decoder.to(device)\n",
    "\n",
    "        if run_mode == \"test\":\n",
    "            pass\n",
    "        elif run_mode == \"chat\":\n",
    "            # Initialize search module\n",
    "            searcher = GreedySearchDecoder(encoder, decoder)\n",
    "            chat(searcher, voc)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Wrong run_mode has been given, options: ['train', 'val', 'test', 'chat']\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"run_mode\": \"train\",\n",
    "    \"model_path\": None,\n",
    "    \"encoder\": \"LSTM\",\n",
    "    \"encoder_direction\": 2,\n",
    "    \"decoder\": \"LSTM\",\n",
    "    \"optimizer\": \"ADAM\",\n",
    "    \"epoch_num\": 50,\n",
    "    \"dropout\": 0.1,\n",
    "    \"gradient_clipping\": 10.0,\n",
    "    \"lr\": 0.001,\n",
    "    \"weight_decay\": 1e-5\n",
    "}\n",
    "\n",
    "print(f\"\\n{'*' * 40}\")\n",
    "print(f\"[RUN_MODE]: {args['run_mode']}\")\n",
    "print(f\"[MODEL_PATH]: {args['model_path']}\")\n",
    "print(f\"{'*' * 40}\\n\")\n",
    "\n",
    "encoder_name = args.get('encoder')\n",
    "decoder_name = args.get('decoder')\n",
    "run_mode = args.get('run_mode')\n",
    "EPOCH_NUM = int(args.get('epoch_num'))\n",
    "\n",
    "# Get device object\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "\n",
    "# Configure attention model\n",
    "attn_model = 'dot'\n",
    "\n",
    "# Base params\n",
    "HIDDEN_SIZE = 300  # Number of dimensions of the embedding; number of features in a hidden state\n",
    "ENCODER_N_LAYERS = 2\n",
    "DECODER_N_LAYERS = 2\n",
    "BATCH_SIZE = 64\n",
    "BIDIRECTION = True\n",
    "\n",
    "# Hyperparameters\n",
    "CLIP = float(args.get('gradient_clipping'))\n",
    "LR = float(args.get('lr'))\n",
    "DROPOUT = float(args.get('dropout'))\n",
    "WD = float(args.get(\"weight_decay\"))\n",
    "\n",
    "main()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}